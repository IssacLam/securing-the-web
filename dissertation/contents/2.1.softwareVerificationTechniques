\subsection{Software Verification Techniques}

\subsubsection{Static Analysis}
% Comparing Model Checking and Static Program Analysis: A Case Study in Error Detection Approaches
It refers to a family of techniques determining the run-time properties of a program without execution \cite{4544862}. With an approximation of the fixpoint collecting semantics, it can indicate run-time errors automatically at compilation time without any code instrumentation or user interaction \cite{vorobyov2010comparing, CousotEtAl10-FMSD}. However, the capability of static analysers can be various depended on techniques implemented. Sometimes predefined facts or patterns are often used for efficiently showing the absence of simple errors, which can be found in compiler optimisation, such as Clang\footnote{A C language family front-end for LLVM: http://clang.llvm.org/}, GCC\footnote{The GNU Compiler Collection: https://gcc.gnu.org/}. Besides that, there are two well-known static analysis techniques, \textit{Abstract Interpretation} and \textit{Model Checking}, that are widely researched and capable of analysing large size software systems with minimal manual effort.

\paragraph{Model Checking} is a formal technique to examine each reachable states whether a correctness property holds without execution and generate a counterexample once a violation exists, which will be discussed in detail in Section~\ref{sec:mc}. 

\paragraph{Abstract Interpretation} is a theory of semantics approximation to predict the program behaviour by using an abstract domain instead of the actual domain of the execution\cite{4544862}. It guarantees a full coverage of the analysis by over-approximating the possible execution paths, therefore no bugs will be missed\cite{CousotCousot09-Marktoberdorf}. However, the accuracy of the analysis relies on the approximation, which becomes a limitation to static analysis. Due to the undecidability of static analysis, it is not possible to come up with an approximation that produces no false positive and no false negative detections, which means no false alarms\cite{4544862}. Moreover, it is difficult to generate counterexamples as the precision loss during the analysis which is a significant trade-off for efficiency.

Despite the weakness above, the performance and the scalability of abstract interpretation are beneficial to the industry as some abstract interpretation-based analysers, such as \textbf{ASTR\'EE}, have been successfully applied to the verification of safety-critical software, such as flight and rocket control system. Moreover, a study conducted by P. Cousot et al. \cite{CousotEtAl10-FMSD} further uses ASTR\'EE as an example to claims that such a difficulty of abstract interpretation has been overcome by domain-specific static analysers. 

\subsubsection{Human-directed Analysis}
As its name suggested, refers to techniques relied on human assistance to determine the software correctness by using mathematical proof. \textbf{Deductive Verification} is an example of such technique to verify the correctness of a program by expressing them into a set of mathematical statements, such that the validity can then be proven by deduction \cite{Filliatre2011, Hahnle_introductiondeductive}. In contrast to static analysis and model checking, it can be the most precise way to model the program behaviour without abstracting any data structures and instructions as expressed in the triangle model in Figure~\ref{fig:tmsv}. However, the price of such precision is relatively high as it requires a huge amount of human effort to construct the inductive arguments as well as computing resources to achieve the verification. This technique is intended to trade off automation for precision by heavily relying on human interaction during the theorem proving process. Hence, it is capable of verifying the functional correctness, but, hardly to be scaled up for large size system \cite{CousotCousot09-Marktoberdorf}. 

% \textbf{VCC} \footnote{VCC github repository: https://github.com/Microsoft/vcc} refers to a Verifier for Concurrent C that was established in December 2008 by Microsoft Research.

\subsubsection{Dynamic Analysis}
\label{subsubseb:d}
% very useful paper, about abstraction
% The concept of dynamic analysis
It refers to techniques that test and evaluate a program by running it. It can derive the correctness properties that hold for a certain number of executions, but not for all executions, which is in contrast to static analysis mentioned above \cite{Ball:1999:CDA:318774.318944}. Although it is not able to prove that a particular property holds, violations of properties can still be detected as well as provide some useful information about the program behaviour. This technique is easier and cheaper to carry out comparing with other formal verification techniques as it generally requires less knowledge than formal method does. Therefore, various testing techniques exist and commonly be used in the software industry. 

% Concolic Testing of the Multi-sector Read Operation for Flash Memory File System
% comparing concolic testing with model checking
\textbf{Concolic testing} is a hybrid software verification technique combining symbolic static analysis and concrete dynamic analysis, which is able to generate test cases automatically and to examine execution paths exhaustively. M. Kim et al. \cite{Kim:2009:CTM:1693660.1693677} conducted an experiment on concolic testing to analyse the multi-sector read operation for a flash memory and summarised its advantages and weaknesses compared to model checking techniques. Concolic testing algorithm in general consists of five steps: 1) Instrumentation, 2) Concrete execution, 3) Symbolic execution, 4) Deciding the next execution path, and 5) Choosing the next input values. As the symbolic execution performs along the concrete execution path, it can prevent any false alarms be created. Once the path formulas are not able to be solved by a constraint solver, some symbolic constraints will be simplified by replacing some of the symbolic values with concrete value. This may lead to an incomplete coverage. The experimental result showed it had a better applicability and lower memory usage. However, the study also reflected that concolic testing is a time-consuming method as time will be wasted on generating invalid test cases in a complex environment model. %Concolic testing can analyse a software with underlying binary libraries without any manual abstraction, which is necessary for model checking. 
Concolic testing can be a good choice for finding bugs, but not for demonstrating program correctness. Comparatively, model checking generally provides high accuracy and a better performance of the verification than concolic testing, which is essential for verifying critical software.